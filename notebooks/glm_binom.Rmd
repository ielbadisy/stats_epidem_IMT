---
title: "GLM binomial"
author: "EL BADISY Imad"
date: "`r Sys.Date()`"
output:
  pdf_document: default
---

# Problématique : Cancer de la prostate 

Le traitement du cancer de la prostate varie en fonction de l'état des nœuds lymphatiques entourant la prostate. Pour éviter une opération chirurgicale lourde qui consiste à l'ouverture de la cavité abdominale, les médecins peuvent faire une évaluation préalable de l'état des nœuds lymphatiques en fonction de certains variables explicatives. Dans cette application nous allons modéliser la variable binaire Y en fonction des variables explicatives suivantes : 


`Y`(Y = 0 si le cancer n’a pas atteint le réseau lymphatique ; Y = 1 si le cancer a atteint le réseau lymphatique) 

`age` : âge du patient au moment du diagnostic

`acide` niveau d’acide phosphatase sérique

`rayonx` : résultat d’une analyse par rayon (0= négatif, 1=positif) 

`taille` : taille de la tumeur (0=petite, 1=grande) 

`grade` : état pathologique de la tumeur déterminé par biopsie (0=moyen, 1=grave) 

`log.acid` : logarithme népérien du niveau d’acidité.


## Application 

1- Dans un document RMarkdown, Chargez le datset `cancerprostate` à partir de votre répertoire de travail. 

2- Vérifiez la structure du dataset avec la fonction `str()` et transformez les variables suivantes en format `factor` : `Y`, `rayonx`, `taille` et `grade`.
```{r}
cancerprostate <- read.csv("~/Desktop/STAT2/STAT_Teaching/stat_epidem_git/datasets/cancerprostate.txt", sep=";")
View(cancerprostate)
```

3- Vérifiez la structure du dataset avec la fonction `str()` et transformez les variables suivantes en format `factor` : `Y`, `rayonx`, `taille` et `grade`.
```{r}
str(cancerprostate)
for (i in 3:6) cancerprostate [, i] <- factor(cancerprostate[,i])
summary(cancerprostate)
```

4- A l'aide de la fonction `glm()` estimez un modèle de régression logistique en expliquant `Y` en fonction de `log.acid`.
```{r}
m1 <- glm(Y~log.acid, data = cancerprostate, family = binomial)
summary(m1)
```


$$Y = \beta_0 + \beta_1 X_1 + ...... + \beta_i X_i$$


5- Interprétez le coefficient de régression associé à la variable `log.acid`.
```{r}
exp(coef(m1))
```

Une augmentation de 1 unité de log.acid se traduira par une multiplication de l'odds-ratio de $p(Y = 1)$ par 9.4 fois (exp(log.acif) = 9.43).


6- Représentez graphiquement les valeurs estimées de la $p(log.acid)$.
```{r}
beta <- coef(m1) #coefficients du modéle
summary(cancerprostate)
summary(cancerprostate)

x <- seq(-2, 2, by=0.01) #générer une séquence de valeurs entre -2 et 2 en allant à un pas de 0.01   

y <- exp(beta[1] + beta[2]*x  ) / (1 + exp(beta[1] + beta[2]*x)) #voir l'équation du modèle !


plot(x, y, type = "l", xlab ="log.acid", ylab ="p(Y=1)")
abline(h = 0.5, lty = 2)
xlim <- -beta[1]/beta[2]
abline(v = xlim, lty = 2)
```
Pour les valeurs de $log.acid > -0.18$, le modèle prédira donc la valeur Y = 1 (i.e. le cancer a atteint le réseau lymphatique). Alors que pour des valeurs $log.acid \leq -0.18$, il prédira Y = 0 (i.e. le cancer n'a pas atteint le réseau lymphatique)

7- Construisez un autre modèle logistique en introduisant un terme d'interaction entre `age` et `grade`.
```{r}
m2 <- glm(Y ~ age + grade + age:grade, data = cancerprostate, family = binomial )
summary(m2)
```
Il semble qu'il n y a aucune relation statistiquement significative entre l'âge et le grade du cancer (la p-value associée au coefficient d'interaction est > 0.05). 

8- Estimez un modèle complet en incluant toutes les covariables.
```{r}
res.complet <- glm( Y ~ ., data = cancerprostate, family = binomial ) 
summary(res.complet)
```

9- Procédez à une sélection automatisée du meilleur modèle. A l'aide de la fonction `step()` choisissez la direction `backward`. Ensuite estimez un modèle final avec les variables sélectionnées en le nommant `select.model`.
Une des méthodes pour déterminer l'importance d'une variable dans un modèle est de tester le changement entre un modèle avec cette variable (i.e. modèle complet) et un modèle sans cette variable (i.e. modèle vide). Cependant, dans le cas de plusieurs covariables, il devient fastidieux d'en faire une sélection manuelle. C'est pour cela, une sélection automatisée du "meilleur modèle" est prévilégiée. 

Le critère de sélection est l'information d'AIC (Akaike Information Criterion). La séléction peut avoir deux sens : 

- Sélection ascencedante : Maximisation de l'AIC
- Sélection descendante : Minimisation de l'AIC

La procédure `backward` : procédure descendante où à chaque étape, on enlève du modèle complet la variable qui a la plus petite minimisation de l'AIC (i.e. dont le retrait du modéle conduit à la minimisation la plus grande de l'AIC). Le processus s'arrête lorsque toutes les variables sont retirées ou lorsque le retrait d'aucune variable ne permet plus de minimiser le critère d'AIC. 

```{r}
select.model <- step(res.complet, direction = "backward")
select.model
```

10- Prédiction des probabilités pour des nouveaux cas.

Nous disposons des données pour 4 nouveaux individus et nous souhaitons prédire leurs probabilités de Y en utilisant notre modèle séléctionné. 

Individu 1 : 61, 0.6, 1, 0, 1, -0.5

Individu 2 : 49, 0.86, 0, 0, 1, -0.15

Individu 3 : 67, 0.72, 1, 0, 1, -0.33

Individu 4 : 51, 0.95, 1, 1, 1, -0.05


A l'aide de la fonction `predict()`, estimez les probabilités pour les nouveaux cas.

- Etape 1 : Création du dataframe des nouvelles observations

- Etape 2 : Prédiction des probabilités $P(Y=1 | X=x_i)$ pour chaucn des nouveaux individus

On utilisera la fonction `predict()` pour pour estimer les valeurs prédites par le modèle pour les observations actuelles ou futures. Il est nécessaire de d'indiquer quel type de prédictions nous souhaitons obtenir : des valeurs exprimées à l'échelle du log-odds (`type = "link"`) ou en termes de probabilités de réponse (`type = "response"`). 

10- Le concept de mal-classés correspond à la proportion d'erreurs commises par le modèle. C'est une information qui nous permet d'avoir une idée sur la précision d'estimation du modèle, surtout quand il s'agit de nouvelles observations. Estimez le taux de mal-classés en trois étapes : 
(i) claculez les probabilités prédites pour chaque individus de l'échantillon 
(ii) récupèrez dans un objet les observations des individus de l'échantillon dont la probabilité estimée est > 0.5  
(iii) dressez un tableau de contingence entre les observations observées et les observations prédites.   


- Etape 1 : Création du dataframe des nouvelles observations
```{r}
new.data <- data.frame(matrix(c(61, 0.6, 1, 0, 1, -0.5, 49, 0.86, 0, 0, 1, -0.15, 67, 0.72, 1, 0, 1, -0.33, 51, 0.95, 1, 1, 1, -0.05), ncol = 6, byrow = T)) #créer une matrice de nouvelles données et convertir son objet en dataframe

names(new.data) <- names(cancerprostate)[-6] #affecter les mêmes noms des variables aux dataframe des nouvelles données

for (i in 3:5) new.data [, i] <- factor(new.data[,i])
```

- Etape 2 : Prédiction des probabilit?s $P(Y=1 | X=x_i)$ pour chaucn des nouveaux individus

On utilisera la fonction _predict()_ pour estimer les valeurs prédites par le modèle sélectionné pour les observations actuelles ou futures. Il est nécessaire d'indiquer quel type de prédictions nous souhaitons obtenir : des valeurs exprimées à l'échelle du log-odds (type = "link") ou en termes de probabilités de réponse (type = "response"). 
```{r}
prevision <- predict(select.model, newdata = new.data, type = "response") #Obtenir les valeurs prédites avec la fonction predict()
prevision
```

Pour les deux premiers individus, les probabilités prédites sont < 0.5, le modèle prédira donc Y = 0, càd que le cancer n'a pas atteint le réseau lymphatique, tandis que pour les deux derniers individus le modèle prédira que le cancer a atteint le réseau lymphatique. 

11- Appliquez la technique de validation croisée pour réestimer le taux de mal classés à l'aide de la fonction `cv.glm()`.

- Etape 1 : On clacule les probabilités prédites pour chaque individus de l'échantillon
```{r}
predict.sample <- predict(select.model, newdata = cancerprostate, type = "response")
predict.sample
```

- Etape 2 : On séléctionne les observations des individus de l'échantillon dont la probabilité estimée est > 0.5 
```{r}
predict.label <- as.numeric(predict.sample > 0.5)
```


- Etape 3 : On dresse un tableau de contingence entre les observations observées et les observations prédites
```{r}
table(cancerprostate$Y, predict.label)
```

- Etape 4 : On calcule le taux de mal classés du modèle 
```{r}
MC <- sum(predict.label != cancerprostate$Y)/nrow(cancerprostate) #(5+6)/53
MC
```
Le taux de mal classé est de 0.208, cela veut dire que la probabilité que notre modèle a une erreur d'estimation est de 20%. Ce taux semble être assez optimiste !

11- Appliquez la technique de validation croisée pour réestimer le taux de mal classés à l'aide de la fonction `cv.glm()` (i.e. voir `help(cv.glm)`)

On construit une fonction de coût admettant en entrée les valeurs observées et les valeurs prédites de Y
```{r}
install.packages("boot")
library(boot)

cout <- function (Y_obs, prevision_pr)
        return(mean(abs(Y_obs - prevision_pr) > 0.5))  #construction d'une fonction de co?t admettant en entr?e les valeurs observ?es de Y et les pr rédites

cv.glm(cancerprostate, select.model, cout)$delta[1]
```

